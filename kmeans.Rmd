---
title: "Coding a K-Means Algorithm"
author: "Lathan Liou"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(ggplot2)
```

# What is K-Means Clustering
K-means clustering is an unsupervised machine learning algorithm that defines "clusters" in a set of data points by minimizing Euclidean distance between a data point and a centroid. A centroid can be loosely defined as a center of mass in a set of points. Each cluster will contain points that are within a similar distance away from a local centroid for that cluster. While there are different algorithmic approaches, the basic idea is the following:

\begin{enumerate}

\list Initialize clusters by choosing _k_ and centroids. 

\list Calculate a distance matrix.

\list Assign clusters by minimum distance.

\list Compute error.

\list Update centroids.

\list Optional: Optimize k by making an elbow plot.

\end{enumerate}

# Randomly generating data points
The first thing to do is to get some data. This data will be slightly contrived, so although it may not highlight the true power of k-means clustering to partition through "messy data", for the purposes of demonstrating how the algorithm works, this is what I'll do.

```{r}
#create data from 3 distinct pools
set.seed(47)
x1 <- runif(50, 1, 50)
y1 <- runif(50, 1, 50)
x2 <- runif(50, 40, 70)
y2 <- runif(50, 40, 70)
x3 <- runif(50, 60, 90)
y3 <- runif(50, 60, 90)

#combine
x <- c(x1, x2, x3)
y <- c(y1, y2, y3)

#create df
df <- cbind(x,y)
df <- as.data.frame(df)

#plot
ggplot(data = df, aes(x, y)) + 
  geom_point() + 
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        panel.background = element_blank(), axis.line = element_line(colour = "black"))
```

Great, so now we have our data. Let's begin coding the k-means algorithm.

```{r}
#define euclidean distance function
euc.dist <- function(x1, x2){
  distance <- sqrt(sum((x1 - x2)^2))
  return(distance)
}

#wrap everything in a function
kmeans <- function(k,runs){
  
  n <- nrow(df)
  
  #choose centroid
  set.seed(47)
  cent.x <- runif(k, 1, 100)
  cent.y <- runif(k, 1, 100)
  centroids <- as.data.frame(cbind(cent.x, cent.y))

#the algorithm
for(i in 1:runs){
   #calculate distance
    dm <- matrix(NA, n, nrow(centroids))
    
    for(j in 1:nrow(centroids)){
      for(i in 1:n){
        dm[i,j] <- euc.dist(df[i,], centroids[j,])
      }
    }
    dm <- as.data.frame(dm)
    
    #find clusters
    clust <- NULL
    clust <- apply(dm, 1, which.min)
    
    #bind cluster assignment to original dataframe
    df_new <- cbind(df, clust)
    
    #recalculate new centroids
    for(i in 1:k){
      test <- df_new %>%
        filter(clust == i) %>%
        colMeans()
      test <- t(as.matrix(test))[,-3]
      centroids[i,] <- test
    }
}
  #plot
    print(ggplot(data = df_new, aes(x,y)) + 
      geom_point(col = clust) + 
      theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        panel.background = element_blank(), axis.line = element_line(colour = "black")))
}
```